{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-r82tFrne0j",
        "outputId": "3670f7c2-c5ce-405c-fb42-67dc9614e3d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#구글 드라이브 연동\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ob81wzgknizb",
        "outputId": "90b41ffa-9d18-4ac1-b9dd-eeb211635c1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285398 sha256=42f254dbc3d7200f2008fb4f62c3c2b13668d04d25810da98ff50d9805cccbd2\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTBBJRv6ni1S"
      },
      "outputs": [],
      "source": [
        "import pyspark\n",
        "from pyspark import SparkConf\n",
        "from pyspark import SparkContext\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import SQLContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ILSEsrwni3a"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33g8DIgyni5_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/cosmetic')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6mlYJUkni8Y"
      },
      "outputs": [],
      "source": [
        "new_df = spark.read.option('header', True).option('inferSchema', True).csv('/content/drive/MyDrive/cosmetic/new.csv')\n",
        "total = new_df.createOrReplaceTempView('total')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOSMmb6cnr6S",
        "outputId": "fcf171c2-fb05-452e-a502-5cc409b77392"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------+----------+----------+-------------------+-------------+------+-----+-------+------------+\n",
            "|         event_time|event_type|product_id|        category_id|category_code| brand|price|user_id|user_session|\n",
            "+-------------------+----------+----------+-------------------+-------------+------+-----+-------+------------+\n",
            "|2020-01-14 16:15:21|      view|   5865526|1487580008447738866|         null|   cnd| 10.0| 465496|           1|\n",
            "|2020-01-14 16:25:35|      view|   5769989|1487580008447738866|         null|   cnd| 10.0| 465496|           2|\n",
            "|2020-01-14 16:27:31|      view|   5865524|1487580008447738866|         null|   cnd| 10.0| 465496|           2|\n",
            "|2019-12-22 12:50:22|      view|   5746011|1487580009051717646|         null|runail|34.92|2963072|          38|\n",
            "|2019-12-22 12:50:45|      view|   5707747|1487580009051717646|         null|  null|73.02|2963072|          38|\n",
            "|2019-12-22 12:50:58|      view|   5746011|1487580009051717646|         null|runail|34.92|2963072|          38|\n",
            "|2019-12-22 12:53:12|      view|   5707747|1487580009051717646|         null|  null|73.02|2963072|          38|\n",
            "|2019-12-22 12:54:34|      view|   5841190|1487580009051717646|         null|  null|47.59|2963072|          38|\n",
            "|2019-12-22 12:55:04|      view|   5707747|1487580009051717646|         null|  null|73.02|2963072|          38|\n",
            "|2019-12-22 12:55:17|      view|   5707747|1487580009051717646|         null|  null|73.02|2963072|          38|\n",
            "+-------------------+----------+----------+-------------------+-------------+------+-----+-------+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 컬럼 확인\n",
        "item = spark.sql(\"\"\"\n",
        "SELECT *\n",
        "FROM total\n",
        "limit 10;\n",
        "\"\"\")\n",
        "item.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl9GOBPxoD-I",
        "outputId": "e17fe66d-cf3d-4476-90d2-29643def98eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------------+\n",
            "|count(DISTINCT user_id)|\n",
            "+-----------------------+\n",
            "|                1639358|\n",
            "+-----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 컬럼 확인\n",
        "result = spark.sql(\"\"\"\n",
        "SELECT count(distinct user_id)\n",
        "FROM new\n",
        "\"\"\")\n",
        "result.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DywCWSqoD_-",
        "outputId": "c3ccf49a-9251-4a3a-e382-e926f3507396"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+-------+-----+-------+\n",
            "|total_cnt|   zero| once|repurch|\n",
            "+---------+-------+-----+-------+\n",
            "|  1639358|1528840|86607|  23911|\n",
            "+---------+-------+-----+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 고객구분 (0회/1회/2회 구매자)\n",
        "# with절 -> purch_cnt(구매한 회원)\n",
        "result = spark.sql(\"\"\"\n",
        "WITH purch_cnt AS (\n",
        "  SELECT user_id\n",
        "\t\t\t , COUNT(DISTINCT user_session) AS session_cnt\n",
        "  FROM total\n",
        "  WHERE event_type = 'purchase'\n",
        "  GROUP BY user_id\n",
        ")\n",
        "SELECT (SELECT COUNT(DISTINCT user_id) FROM new) AS total_cnt\n",
        "\t\t , (SELECT COUNT(DISTINCT user_id) FROM new) - (SELECT COUNT(user_id) FROM purch_cnt) AS zero\n",
        "\t\t , (SELECT COUNT(user_id) FROM purch_cnt WHERE session_cnt=1) AS once\n",
        "\t\t , (SELECT COUNT(user_id) FROM purch_cnt WHERE session_cnt>=2) AS repurch\n",
        "\"\"\")\n",
        "result.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwuXb6YToFGx"
      },
      "source": [
        "## 1. 코호트 분석: 코호트별 매출 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcrLjtzILfB2",
        "outputId": "ec9da856-24e0-42bd-fbfb-5c941283eed1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------+------------------+--------------------+-------------------+------------------+------------------+-----------------+--------------------+\n",
            "|first_order_month|              day0|               day25|              day50|             day75|            day100|           day125|              day150|\n",
            "+-----------------+------------------+--------------------+-------------------+------------------+------------------+-----------------+--------------------+\n",
            "|       2019-10-01| 82.44534702274667|  10.061702119400667|   6.62087415573325| 6.174474419687912| 6.565313252076702|3.432294852884093|0.027665553916621382|\n",
            "|       2019-11-01|59.991043309293374|   3.802795485968387|   4.35885953439707|3.9113766301707713|1.0517136878293039|             null|                null|\n",
            "|       2019-12-01|46.174096030859815|  3.3481519642675868| 2.4661019185869453|0.5556811491219166|              null|             null|                null|\n",
            "|       2020-01-01| 47.17331473050375|    2.86712243599158|0.21073040583541391|              null|              null|             null|                null|\n",
            "|       2020-02-01|41.930012873614686|0.042693384081495575|               null|              null|              null|             null|                null|\n",
            "+-----------------+------------------+--------------------+-------------------+------------------+------------------+-----------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# try 1\n",
        "# 매출을 COUNT(DISTINCT user_id)로 나눔.\n",
        "# 고객당 평균 매출 = 코호트 매출 / 코호트 내 고객수\n",
        "\n",
        "result = spark.sql(\"\"\"\n",
        "WITH customers AS (\n",
        "  SELECT user_id\n",
        "       ,MIN(event_time) AS first_order_day\n",
        "       ,MAX(event_time) AS last_order_day\n",
        "  FROM total\n",
        "  WHERE event_type = 'purchase'\n",
        "  GROUP BY user_id\n",
        "), records_month AS (\n",
        "  SELECT to.user_id\n",
        "      ,DATE_FORMAT(first_order_day, 'yyyy-MM-01') as first_order_month\n",
        "      ,DATE_FORMAT(cu.first_order_day, 'yyyy-MM-dd') AS first_order_date\n",
        "      ,DATE_FORMAT(cu.last_order_day, 'yyyy-MM-dd') AS last_order_date\n",
        "      ,DATE_FORMAT(event_time, 'yyyy-MM-dd') as order_date\n",
        "      ,price\n",
        "  FROM total as to\n",
        "    INNER JOIN customers cu ON to.user_id = cu.user_id AND event_type = 'purchase')\n",
        "SELECT first_order_month\n",
        "     ,ROUND(sum(price),2) / COUNT(DISTINCT user_id) day0\n",
        "      ,ROUND(SUM(CASE WHEN order_date >= DATE_ADD(first_order_date, 25)\n",
        "                          AND order_date < DATE_ADD(first_order_date, 50) THEN price END),2) / COUNT(DISTINCT user_id) day25\n",
        "      ,ROUND(SUM(CASE WHEN order_date >= DATE_ADD(first_order_date, 50)\n",
        "                          AND order_date < DATE_ADD(first_order_date, 75) THEN price END),2) / COUNT(DISTINCT user_id) day50\n",
        "      ,ROUND(SUM(CASE WHEN order_date >= DATE_ADD(first_order_date, 75)\n",
        "                          AND order_date < DATE_ADD(first_order_date, 100) THEN price END),2) / COUNT(DISTINCT user_id) day75\n",
        "      ,ROUND(SUM(CASE WHEN order_date >= DATE_ADD(first_order_date, 100)\n",
        "                          AND order_date < DATE_ADD(first_order_date, 125) THEN price END),2) / COUNT(DISTINCT user_id) day100\n",
        "      ,ROUND(SUM(CASE WHEN order_date >= DATE_ADD(first_order_date, 125)\n",
        "                          AND order_date < DATE_ADD(first_order_date, 150) THEN price END),2) / COUNT(DISTINCT user_id) day125\n",
        "      ,ROUND(SUM(CASE WHEN order_date >= DATE_ADD(first_order_date, 150)\n",
        "                          AND order_date < DATE_ADD(first_order_date, 175) THEN price END),2) / COUNT(DISTINCT user_id) day150\n",
        "\n",
        "FROM records_month\n",
        "GROUP BY first_order_month\n",
        "ORDER BY first_order_month\n",
        "\n",
        "\"\"\")\n",
        "result.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hP1gS6PXr0Hd",
        "outputId": "72745373-e837-4767-9291-25c281606704"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------+------------------+-----+-----+-----+------+------+------+\n",
            "|first_order_month|              day0|day25|day50|day75|day100|day125|day150|\n",
            "+-----------------+------------------+-----+-----+-----+------+------+------+\n",
            "|       2019-10-01| 82.44534702274667|10.06| 6.62| 6.17|  6.57|  3.43|  0.03|\n",
            "|       2019-11-01|59.991043309293374|  3.8| 4.36| 3.91|  1.05|  null|  null|\n",
            "|       2019-12-01|46.174096030859815| 3.35| 2.47| 0.56|  null|  null|  null|\n",
            "|       2020-01-01| 47.17331473050375| 2.87| 0.21| null|  null|  null|  null|\n",
            "|       2020-02-01|41.930012873614686| 0.04| null| null|  null|  null|  null|\n",
            "+-----------------+------------------+-----+-----+-----+------+------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# try 2\n",
        "# 고객당 평균 매출 (반올림)\n",
        "\n",
        "result = spark.sql(\"\"\"\n",
        "WITH customers AS (\n",
        "  SELECT user_id\n",
        "       ,MIN(event_time) AS first_order_day\n",
        "       ,MAX(event_time) AS last_order_day\n",
        "  FROM total\n",
        "  WHERE event_type = 'purchase'\n",
        "  GROUP BY user_id\n",
        "), records_month AS (\n",
        "  SELECT to.user_id\n",
        "      ,DATE_FORMAT(first_order_day, 'yyyy-MM-01') as first_order_month\n",
        "      ,DATE_FORMAT(cu.first_order_day, 'yyyy-MM-dd') AS first_order_date\n",
        "      ,DATE_FORMAT(cu.last_order_day, 'yyyy-MM-dd') AS last_order_date\n",
        "      ,DATE_FORMAT(event_time, 'yyyy-MM-dd') as order_date\n",
        "      ,price\n",
        "  FROM total as to\n",
        "    INNER JOIN customers cu ON to.user_id = cu.user_id AND event_type = 'purchase')\n",
        "SELECT first_order_month\n",
        "     ,ROUND(sum(price) / COUNT(DISTINCT user_id),2) day0\n",
        "      ,ROUND(SUM(CASE WHEN order_date >= DATE_ADD(first_order_date, 25)\n",
        "                          AND order_date < DATE_ADD(first_order_date, 50) THEN price END) / COUNT(DISTINCT user_id),2) day25\n",
        "      ,ROUND(SUM(CASE WHEN order_date >= DATE_ADD(first_order_date, 50)\n",
        "                          AND order_date < DATE_ADD(first_order_date, 75) THEN price END) / COUNT(DISTINCT user_id),2) day50\n",
        "      ,ROUND(SUM(CASE WHEN order_date >= DATE_ADD(first_order_date, 75)\n",
        "                          AND order_date < DATE_ADD(first_order_date, 100) THEN price END) / COUNT(DISTINCT user_id),2) day75\n",
        "      ,ROUND(SUM(CASE WHEN order_date >= DATE_ADD(first_order_date, 100)\n",
        "                          AND order_date < DATE_ADD(first_order_date, 125) THEN price END) / COUNT(DISTINCT user_id),2) day100\n",
        "      ,ROUND(SUM(CASE WHEN order_date >= DATE_ADD(first_order_date, 125)\n",
        "                          AND order_date < DATE_ADD(first_order_date, 150) THEN price END) / COUNT(DISTINCT user_id),2) day125\n",
        "      ,ROUND(SUM(CASE WHEN order_date >= DATE_ADD(first_order_date, 150)\n",
        "                          AND order_date < DATE_ADD(first_order_date, 175) THEN price END) / COUNT(DISTINCT user_id),2) day150\n",
        "\n",
        "FROM records_month\n",
        "GROUP BY first_order_month\n",
        "ORDER BY first_order_month\n",
        "\n",
        "\"\"\")\n",
        "result.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sr_pKg4ar0Jz",
        "outputId": "88554a4f-bfff-4f82-dc7b-db01f2f7540b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------+----------+---------+---------+---------+--------+--------+------+\n",
            "|first_order_month|      day0|    day25|    day50|    day75|  day100|  day125|day150|\n",
            "+-----------------+----------+---------+---------+---------+--------+--------+------+\n",
            "|       2019-10-01|2123957.03|259209.57|170566.96|159066.81|169135.6|88422.78|712.72|\n",
            "|       2019-11-01|1605420.31|101766.61|116647.44|104672.35|28144.91|    null|  null|\n",
            "|       2019-12-01| 909722.04| 65965.29| 48587.14| 10948.03|    null|    null|  null|\n",
            "|       2020-01-01|  963609.3| 58566.71|  4304.59|     null|    null|    null|  null|\n",
            "|       2020-02-01| 749121.61|   762.76|     null|     null|    null|    null|  null|\n",
            "+-----------------+----------+---------+---------+---------+--------+--------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#코호트별 기간 매출액\n",
        "result = spark.sql(\"\"\"\n",
        "WITH customers AS (\n",
        "  SELECT user_id\n",
        "       ,MIN(event_time) AS first_order_day\n",
        "       ,MAX(event_time) AS last_order_day\n",
        "  FROM total\n",
        "  WHERE event_type = 'purchase'\n",
        "  GROUP BY user_id\n",
        "), records_month AS (\n",
        "  SELECT to.user_id\n",
        "      ,DATE_FORMAT(first_order_day, 'yyyy-MM-01') as first_order_month\n",
        "      ,DATE_FORMAT(cu.first_order_day, 'yyyy-MM-dd') AS first_order_date\n",
        "      ,DATE_FORMAT(cu.last_order_day, 'yyyy-MM-dd') AS last_order_date\n",
        "      ,DATE_FORMAT(event_time, 'yyyy-MM-dd') as order_date\n",
        "      ,price\n",
        "  FROM total as to\n",
        "    INNER JOIN customers cu ON to.user_id = cu.user_id AND event_type = 'purchase')\n",
        "\n",
        "SELECT first_order_month\n",
        "     ,ROUND(sum(price),2) day0\n",
        "      ,ROUND(SUM(CASE WHEN order_date >= DATE_ADD(first_order_date, 25)\n",
        "                          AND order_date < DATE_ADD(first_order_date, 50) THEN price END),2) day25\n",
        "      ,ROUND(SUM(CASE WHEN order_date >= DATE_ADD(first_order_date, 50)\n",
        "                          AND order_date < DATE_ADD(first_order_date, 75) THEN price END),2) day50\n",
        "      ,ROUND(SUM(CASE WHEN order_date >= DATE_ADD(first_order_date, 75)\n",
        "                          AND order_date < DATE_ADD(first_order_date, 100) THEN price END),2) day75\n",
        "      ,ROUND(SUM(CASE WHEN order_date >= DATE_ADD(first_order_date, 100)\n",
        "                          AND order_date < DATE_ADD(first_order_date, 125) THEN price END),2) day100\n",
        "      ,ROUND(SUM(CASE WHEN order_date >= DATE_ADD(first_order_date, 125)\n",
        "                          AND order_date < DATE_ADD(first_order_date, 150) THEN price END),2) day125\n",
        "      ,ROUND(SUM(CASE WHEN order_date >= DATE_ADD(first_order_date, 150)\n",
        "                          AND order_date < DATE_ADD(first_order_date, 175) THEN price END),2) day150\n",
        "\n",
        "FROM records_month\n",
        "GROUP BY first_order_month\n",
        "ORDER BY first_order_month\n",
        "\n",
        "\"\"\")\n",
        "result.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "518jpXLer2GB",
        "outputId": "2be38da7-e1cd-414d-881e-9f8738005c1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------+-----+-----+-----+-----+------+------+------+\n",
            "|first_order_month| day0|day25|day50|day75|day100|day125|day150|\n",
            "+-----------------+-----+-----+-----+-----+------+------+------+\n",
            "|       2019-10-01|82.45|63.44|56.61|58.29| 63.92| 63.66| 50.91|\n",
            "|       2019-11-01|59.99|48.16|52.28|55.12| 51.83|  null|  null|\n",
            "|       2019-12-01|46.17|47.84|47.08|45.24|  null|  null|  null|\n",
            "|       2020-01-01|47.17|52.91|57.39| null|  null|  null|  null|\n",
            "|       2020-02-01|41.93|34.67| null| null|  null|  null|  null|\n",
            "+-----------------+-----+-----+-----+-----+------+------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# final 수정본\n",
        "# 고객당 평균 매출 = 각 구간별 인원수 / 구간별 총매출\n",
        "result = spark.sql(\"\"\"\n",
        "WITH customers AS (\n",
        "  SELECT user_id\n",
        "       , MIN(event_time) AS first_order_day\n",
        "       , MAX(event_time) AS last_order_day\n",
        "  FROM total\n",
        "  WHERE event_type = 'purchase'\n",
        "  GROUP BY user_id\n",
        "), records_month AS (\n",
        "  SELECT to.user_id\n",
        "      , DATE_FORMAT(first_order_day, 'yyyy-MM-01') as first_order_month\n",
        "      , DATE_FORMAT(cu.first_order_day, 'yyyy-MM-dd') AS first_order_date\n",
        "      , DATE_FORMAT(cu.last_order_day, 'yyyy-MM-dd') AS last_order_date\n",
        "      , DATE_FORMAT(event_time, 'yyyy-MM-dd') as order_date\n",
        "      , price\n",
        "  FROM total as to\n",
        "    INNER JOIN customers cu ON to.user_id = cu.user_id AND event_type = 'purchase'\n",
        ")\n",
        "\n",
        "SELECT first_order_month\n",
        "     , ROUND(SUM(price) / COUNT(DISTINCT user_id), 2) as day0\n",
        "     , ROUND(SUM(CASE WHEN order_date >= DATE_ADD(first_order_date, 25)\n",
        "                          AND order_date < DATE_ADD(first_order_date, 50) THEN price END) / COUNT(DISTINCT CASE WHEN order_date >= DATE_ADD(first_order_date, 25)\n",
        "                          AND order_date < DATE_ADD(first_order_date, 50) THEN user_id END), 2) as day25\n",
        "     , ROUND(SUM(CASE WHEN order_date >= DATE_ADD(first_order_date, 50)\n",
        "                          AND order_date < DATE_ADD(first_order_date, 75) THEN price END) / COUNT(DISTINCT CASE WHEN order_date >= DATE_ADD(first_order_date, 50)\n",
        "                          AND order_date < DATE_ADD(first_order_date, 75) THEN user_id END), 2) as day50\n",
        "     , ROUND(SUM(CASE WHEN order_date >= DATE_ADD(first_order_date, 75)\n",
        "                          AND order_date < DATE_ADD(first_order_date, 100) THEN price END) / COUNT(DISTINCT CASE WHEN order_date >= DATE_ADD(first_order_date, 75)\n",
        "                          AND order_date < DATE_ADD(first_order_date, 100) THEN user_id END), 2) as day75\n",
        "     , ROUND(SUM(CASE WHEN order_date >= DATE_ADD(first_order_date, 100)\n",
        "                          AND order_date < DATE_ADD(first_order_date, 125) THEN price END) / COUNT(DISTINCT CASE WHEN order_date >= DATE_ADD(first_order_date, 100)\n",
        "                          AND order_date < DATE_ADD(first_order_date, 125) THEN user_id END), 2) as day100\n",
        "     , ROUND(SUM(CASE WHEN order_date >= DATE_ADD(first_order_date, 125)\n",
        "                          AND order_date < DATE_ADD(first_order_date, 150) THEN price END) / COUNT(DISTINCT CASE WHEN order_date >= DATE_ADD(first_order_date, 125)\n",
        "                          AND order_date < DATE_ADD(first_order_date, 150) THEN user_id END), 2) as day125\n",
        "     , ROUND(SUM(CASE WHEN order_date >= DATE_ADD(first_order_date, 150)\n",
        "                          AND order_date < DATE_ADD(first_order_date, 175) THEN price END) / COUNT(DISTINCT CASE WHEN order_date >= DATE_ADD(first_order_date, 150)\n",
        "                          AND order_date < DATE_ADD(first_order_date, 175) THEN user_id END), 2) as day150\n",
        "FROM records_month\n",
        "GROUP BY first_order_month\n",
        "ORDER BY first_order_month;\n",
        "\n",
        "\"\"\")\n",
        "result.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjJNC8nLr2Hb",
        "outputId": "c37234cb-6de8-48d0-d182-2d48b4ca03c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------+-----+-------+--------+--------+---------+----------+----------+\n",
            "|first_order_month| day0|day1_25|day26_50|day51_75|day76_100|day101_125|day126_150|\n",
            "+-----------------+-----+-------+--------+--------+---------+----------+----------+\n",
            "|       2019-10-01|82.45|  46.06|   54.86|   59.62|    54.37|     63.01|      64.1|\n",
            "|       2019-11-01|59.99|  44.98|   44.82|   48.51|    54.75|     53.48|      null|\n",
            "|       2019-12-01|46.17|  38.54|   41.95|   47.37|    44.53|      null|      null|\n",
            "|       2020-01-01|47.17|  41.74|   45.74|   48.39|     null|      null|      null|\n",
            "|       2020-02-01|41.93|  41.88|   38.25|    null|     null|      null|      null|\n",
            "+-----------------+-----+-------+--------+--------+---------+----------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result = spark.sql(\"\"\"\n",
        "WITH purchase_stats AS (\n",
        "  SELECT DISTINCT user_id\n",
        "       , DATE_FORMAT(MIN(event_time), 'yyyy-MM-dd') first_order_date\n",
        "       , DATE_FORMAT(MAX(event_time), 'yyyy-MM-dd') last_order_date\n",
        "  FROM total\n",
        "  WHERE event_type = 'purchase'\n",
        "  GROUP BY user_id\n",
        "), total_preprocessed AS (\n",
        "  SELECT t.user_id\n",
        "       , DATE_FORMAT(t.event_time, 'yyyy-MM-dd') order_date\n",
        "       , ps.first_order_date\n",
        "       , DATE_FORMAT(ps.first_order_date, 'yyyy-MM-01') first_order_month\n",
        "       , t.price\n",
        "  FROM total t\n",
        "       INNER JOIN purchase_stats ps ON t.user_id = ps.user_id AND t.event_type = 'purchase'\n",
        ")\n",
        "\n",
        "SELECT first_order_month\n",
        "     , ROUND(SUM(price) / COUNT(DISTINCT user_id), 2) day0\n",
        "     , ROUND(SUM(CASE WHEN order_date BETWEEN DATE_ADD(first_order_month, 1) AND DATE_ADD(first_order_month, 25) THEN price END) /\n",
        "       COUNT(DISTINCT CASE WHEN order_date BETWEEN DATE_ADD(first_order_month, 1) AND DATE_ADD(first_order_month, 25)\n",
        "       THEN user_id END), 2) day1_25\n",
        "     , ROUND(SUM(CASE WHEN order_date BETWEEN DATE_ADD(first_order_month, 26) AND DATE_ADD(first_order_month, 50) THEN price END) /\n",
        "       COUNT(DISTINCT CASE WHEN order_date BETWEEN DATE_ADD(first_order_month, 26) AND DATE_ADD(first_order_month, 50)\n",
        "       THEN user_id END), 2) day26_50\n",
        "     , ROUND(SUM(CASE WHEN order_date BETWEEN DATE_ADD(first_order_month, 51) AND DATE_ADD(first_order_month, 75) THEN price END) /\n",
        "       COUNT(DISTINCT CASE WHEN order_date BETWEEN DATE_ADD(first_order_month, 51) AND DATE_ADD(first_order_month, 75)\n",
        "       THEN user_id END), 2) day51_75\n",
        "     , ROUND(SUM(CASE WHEN order_date BETWEEN DATE_ADD(first_order_month, 76) AND DATE_ADD(first_order_month, 100) THEN price END) /\n",
        "       COUNT(DISTINCT CASE WHEN order_date BETWEEN DATE_ADD(first_order_month, 76) AND DATE_ADD(first_order_month, 100)\n",
        "       THEN user_id END), 2) day76_100\n",
        "     , ROUND(SUM(CASE WHEN order_date BETWEEN DATE_ADD(first_order_month, 101) AND DATE_ADD(first_order_month, 125) THEN price END) /\n",
        "       COUNT(DISTINCT CASE WHEN order_date BETWEEN DATE_ADD(first_order_month, 101) AND DATE_ADD(first_order_month, 125)\n",
        "       THEN user_id END), 2) day101_125\n",
        "     , ROUND(SUM(CASE WHEN order_date BETWEEN DATE_ADD(first_order_month, 126) AND DATE_ADD(first_order_month, 150) THEN price END) /\n",
        "       COUNT(DISTINCT CASE WHEN order_date BETWEEN DATE_ADD(first_order_month, 126) AND DATE_ADD(first_order_month, 150)\n",
        "       THEN user_id END), 2) day126_150\n",
        "FROM total_preprocessed\n",
        "GROUP BY first_order_month\n",
        "ORDER BY first_order_month\n",
        "\n",
        "\"\"\")\n",
        "result.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfNVfoGnSgU4",
        "outputId": "6e3d5d32-b438-4c0a-e260-bb5b363c57b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+----------+----------------+-----------------+-----+\n",
            "| user_id|order_date|first_order_date|first_order_month|price|\n",
            "+--------+----------+----------------+-----------------+-----+\n",
            "|43713532|2019-10-13|      2019-10-13|       2019-10-01| 6.35|\n",
            "|43713532|2019-10-13|      2019-10-13|       2019-10-01| 1.59|\n",
            "|43713532|2019-10-13|      2019-10-13|       2019-10-01| 1.59|\n",
            "|43713532|2019-10-13|      2019-10-13|       2019-10-01|  1.9|\n",
            "|43713532|2019-10-13|      2019-10-13|       2019-10-01| 3.97|\n",
            "|43713532|2019-10-13|      2019-10-13|       2019-10-01| 3.97|\n",
            "|43713532|2019-10-13|      2019-10-13|       2019-10-01| 3.97|\n",
            "|43713532|2019-10-13|      2019-10-13|       2019-10-01| 3.57|\n",
            "|43713532|2019-10-13|      2019-10-13|       2019-10-01| 5.56|\n",
            "|43713532|2019-10-13|      2019-10-13|       2019-10-01| 6.27|\n",
            "|43713532|2019-10-13|      2019-10-13|       2019-10-01|10.95|\n",
            "|43713532|2019-10-13|      2019-10-13|       2019-10-01| 1.59|\n",
            "|43713532|2019-10-13|      2019-10-13|       2019-10-01| 0.92|\n",
            "|43713532|2019-10-13|      2019-10-13|       2019-10-01| 6.27|\n",
            "|43713532|2019-10-13|      2019-10-13|       2019-10-01| 3.81|\n",
            "|43713532|2019-10-13|      2019-10-13|       2019-10-01| 4.76|\n",
            "|43713532|2019-10-13|      2019-10-13|       2019-10-01| 4.76|\n",
            "|43713532|2019-10-13|      2019-10-13|       2019-10-01| 4.76|\n",
            "|43713532|2019-10-13|      2019-10-13|       2019-10-01| 9.37|\n",
            "|43713532|2019-10-13|      2019-10-13|       2019-10-01| 0.71|\n",
            "+--------+----------+----------------+-----------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result = spark.sql(\"\"\"\n",
        "WITH purchase_stats AS (\n",
        "  SELECT DISTINCT user_id\n",
        "       , DATE_FORMAT(MIN(event_time), 'yyyy-MM-dd') first_order_date\n",
        "       , DATE_FORMAT(MAX(event_time), 'yyyy-MM-dd') last_order_date\n",
        "  FROM total\n",
        "  WHERE event_type = 'purchase'\n",
        "  GROUP BY user_id\n",
        "), total_preprocessed AS (\n",
        "  SELECT t.user_id\n",
        "       , DATE_FORMAT(t.event_time, 'yyyy-MM-dd') order_date\n",
        "       , ps.first_order_date\n",
        "       , DATE_FORMAT(ps.first_order_date, 'yyyy-MM-01') first_order_month\n",
        "       , t.price\n",
        "  FROM total t\n",
        "       INNER JOIN purchase_stats ps ON t.user_id = ps.user_id AND t.event_type = 'purchase'\n",
        ")\n",
        "\n",
        "SELECT *\n",
        "FROM total_preprocessed\n",
        "\"\"\")\n",
        "result.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGcbLu-sg_MV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_Pzb-purzmL"
      },
      "source": [
        "## 2. 리텐션 분석"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mN4liZlJsWZ4",
        "outputId": "0f11ebed-85ec-4577-be09-8145c3a6d7f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----------------+---------------+\n",
            "|  user_id|first_order_date|last_order_date|\n",
            "+---------+----------------+---------------+\n",
            "| 43713532|      2019-10-13|     2019-10-13|\n",
            "|129675214|      2020-01-03|     2020-01-03|\n",
            "|189390340|      2020-02-07|     2020-02-07|\n",
            "|204142009|      2020-01-20|     2020-01-20|\n",
            "|207395269|      2019-11-08|     2020-01-24|\n",
            "|221988388|      2019-12-24|     2019-12-24|\n",
            "|230350829|      2019-10-12|     2020-01-08|\n",
            "|231023829|      2019-12-18|     2020-01-27|\n",
            "|231048129|      2019-11-14|     2020-02-23|\n",
            "|233169997|      2019-12-22|     2019-12-22|\n",
            "|233321490|      2019-11-07|     2019-12-06|\n",
            "|234024900|      2019-10-15|     2020-02-12|\n",
            "|235005368|      2019-12-12|     2020-01-08|\n",
            "|235215029|      2020-01-27|     2020-01-27|\n",
            "|236532316|      2020-02-01|     2020-02-24|\n",
            "|237317205|      2019-11-06|     2019-11-06|\n",
            "|246980024|      2019-11-02|     2019-11-02|\n",
            "|264865866|      2019-10-22|     2020-01-27|\n",
            "|269428285|      2019-10-22|     2020-02-29|\n",
            "|274114452|      2020-01-22|     2020-01-22|\n",
            "+---------+----------------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 1단계\n",
        "result = spark.sql(\"\"\"\n",
        "SELECT user_id\n",
        "       , DATE_FORMAT(MIN(event_time), 'yyyy-MM-dd') AS first_order_date\n",
        "       , DATE_FORMAT(MAX(event_time), 'yyyy-MM-dd') AS last_order_date\n",
        "  FROM total\n",
        "  WHERE event_type = 'purchase'\n",
        "  GROUP BY user_id\n",
        "\"\"\")\n",
        "result.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42Q_Idl5CRlI",
        "outputId": "48f441b4-feff-409e-8100-7be36d325b2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+-----------------+----------+----------------+\n",
            "| user_id|first_order_month|order_date|first_order_date|\n",
            "+--------+-----------------+----------+----------------+\n",
            "|43713532|       2019-10-01|2019-10-13|      2019-10-13|\n",
            "|43713532|       2019-10-01|2019-10-13|      2019-10-13|\n",
            "|43713532|       2019-10-01|2019-10-13|      2019-10-13|\n",
            "|43713532|       2019-10-01|2019-10-13|      2019-10-13|\n",
            "|43713532|       2019-10-01|2019-10-13|      2019-10-13|\n",
            "|43713532|       2019-10-01|2019-10-13|      2019-10-13|\n",
            "|43713532|       2019-10-01|2019-10-13|      2019-10-13|\n",
            "|43713532|       2019-10-01|2019-10-13|      2019-10-13|\n",
            "|43713532|       2019-10-01|2019-10-13|      2019-10-13|\n",
            "|43713532|       2019-10-01|2019-10-13|      2019-10-13|\n",
            "|43713532|       2019-10-01|2019-10-13|      2019-10-13|\n",
            "|43713532|       2019-10-01|2019-10-13|      2019-10-13|\n",
            "|43713532|       2019-10-01|2019-10-13|      2019-10-13|\n",
            "|43713532|       2019-10-01|2019-10-13|      2019-10-13|\n",
            "|43713532|       2019-10-01|2019-10-13|      2019-10-13|\n",
            "|43713532|       2019-10-01|2019-10-13|      2019-10-13|\n",
            "|43713532|       2019-10-01|2019-10-13|      2019-10-13|\n",
            "|43713532|       2019-10-01|2019-10-13|      2019-10-13|\n",
            "|43713532|       2019-10-01|2019-10-13|      2019-10-13|\n",
            "|43713532|       2019-10-01|2019-10-13|      2019-10-13|\n",
            "+--------+-----------------+----------+----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 2단계\n",
        "# processed table만들기\n",
        "result = spark.sql(\"\"\"\n",
        "WITH stats AS (\n",
        "  SELECT user_id\n",
        "       , DATE_FORMAT(MIN(event_time), 'yyyy-MM-dd') AS first_order_date\n",
        "       , DATE_FORMAT(MAX(event_time), 'yyyy-MM-dd') AS last_order_date\n",
        "  FROM total\n",
        "  WHERE event_type = 'purchase'\n",
        "  GROUP BY user_id\n",
        "), processed AS (\n",
        "  SELECT t.user_id\n",
        "       , DATE_FORMAT(s.first_order_date, 'yyyy-MM-01') AS first_order_month\n",
        "       , DATE_FORMAT(t.event_time, 'yyyy-MM-dd') AS order_date\n",
        "       , s.first_order_date\n",
        "  FROM total t\n",
        "    INNER JOIN stats s ON t.user_id = s.user_id AND t.event_type = 'purchase'\n",
        ")\n",
        "SELECT *\n",
        "FROM processed;\n",
        "\n",
        "\"\"\")\n",
        "result.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psp34nfaudY7",
        "outputId": "97faabeb-b0aa-4cb7-860f-4f81c0f3dbf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------------+\n",
            "|count(DISTINCT user_id)|\n",
            "+-----------------------+\n",
            "|                 110518|\n",
            "+-----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 2단계\n",
        "# processed table만들기\n",
        "result = spark.sql(\"\"\"\n",
        "WITH stats AS (\n",
        "  SELECT user_id\n",
        "       , DATE_FORMAT(MIN(event_time), 'yyyy-MM-dd') AS first_order_date\n",
        "       , DATE_FORMAT(MAX(event_time), 'yyyy-MM-dd') AS last_order_date\n",
        "  FROM total\n",
        "  WHERE event_type = 'purchase'\n",
        "  GROUP BY user_id\n",
        "), processed AS (\n",
        "  SELECT t.user_id\n",
        "       , DATE_FORMAT(s.first_order_date, 'yyyy-MM-01') AS first_order_month\n",
        "       , DATE_FORMAT(t.event_time, 'yyyy-MM-dd') AS order_date\n",
        "       , s.first_order_date\n",
        "  FROM total t\n",
        "    INNER JOIN stats s ON t.user_id = s.user_id AND t.event_type = 'purchase'\n",
        ")\n",
        "SELECT count(distinct user_id)\n",
        "FROM processed;\n",
        "\n",
        "\"\"\")\n",
        "result.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0b3u4DnvKYU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHiM1XBQudfu"
      },
      "outputs": [],
      "source": [
        "result = spark.sql(\"\"\"\n",
        "\n",
        "\n",
        "\"\"\")\n",
        "result.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ra-B-T0zudiE"
      },
      "outputs": [],
      "source": [
        "result = spark.sql(\"\"\"\n",
        "\n",
        "\n",
        "\"\"\")\n",
        "result.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 리텐션 (cycle/n-day =25일)\n",
        "- with절 구문 사용\n",
        "  1단계 stats: 구매세션을 id별로 그룹핑하고, 날짜형태를 2020-10-01 로 변경\n",
        "  2단계 processed: 전체 구매리스트에서\n",
        "- 의문점: 애초에 구매횟수에 대한 조건을 건게 아니고\n",
        "- 구매이력이 있는 id 대상으로 리텐션분석한거라 분석제목이 기존고객의 리텐션이라기보다 그냥 리텐션 아닌가..?"
      ],
      "metadata": {
        "id": "UhQPdqmVYdWT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHPwM-XsoECV"
      },
      "outputs": [],
      "source": [
        "result = spark.sql(\"\"\"\n",
        "WITH stats AS (\n",
        "  SELECT user_id\n",
        "       , DATE_FORMAT(MIN(event_time), 'yyyy-MM-dd') AS first_order_date\n",
        "       , DATE_FORMAT(MAX(event_time), 'yyyy-MM-dd') AS last_order_date\n",
        "  FROM total\n",
        "  WHERE event_type = 'purchase'\n",
        "  GROUP BY user_id\n",
        "), processed AS (\n",
        "  SELECT t.user_id\n",
        "       , DATE_FORMAT(s.first_order_date, 'yyyy-MM-01') AS first_order_month\n",
        "       , DATE_FORMAT(t.event_time, 'yyyy-MM-dd') AS order_date\n",
        "       , first_order_date\n",
        "  FROM total t\n",
        "    INNER JOIN stats s ON t.user_id = s.user_id AND t.event_type = 'purchase'\n",
        ")\n",
        "SELECT first_order_month\n",
        "     , COUNT(DISTINCT user_id) AS day0\n",
        "     , COUNT(DISTINCT CASE WHEN order_date >= DATE_ADD(first_order_date, 25) AND order_date < DATE_ADD(first_order_date, 50) THEN user_id END) / COUNT(DISTINCT user_id) AS day25\n",
        "     , COUNT(DISTINCT CASE WHEN order_date >= DATE_ADD(first_order_date, 50) AND order_date < DATE_ADD(first_order_date, 75) THEN user_id END) / COUNT(DISTINCT user_id) AS day50\n",
        "     , COUNT(DISTINCT CASE WHEN order_date >= DATE_ADD(first_order_date, 75) AND order_date < DATE_ADD(first_order_date, 100) THEN user_id END) / COUNT(DISTINCT user_id) AS day75\n",
        "     , COUNT(DISTINCT CASE WHEN order_date >= DATE_ADD(first_order_date, 100) AND order_date < DATE_ADD(first_order_date, 125) THEN user_id END) / COUNT(DISTINCT user_id) AS day100\n",
        "     , COUNT(DISTINCT CASE WHEN order_date >= DATE_ADD(first_order_date, 125) AND order_date < DATE_ADD(first_order_date, 150) THEN user_id END) / COUNT(DISTINCT user_id) AS day125\n",
        "     , COUNT(DISTINCT CASE WHEN order_date >= DATE_ADD(first_order_date, 150) AND order_date < DATE_ADD(first_order_date, 175) THEN user_id END) / COUNT(DISTINCT user_id) AS day150\n",
        "FROM processed\n",
        "GROUP BY first_order_month\n",
        "ORDER BY first_order_month\n",
        "\n",
        "\"\"\")\n",
        "result.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4oUxbQjsrT9",
        "outputId": "3170e939-5196-4b4e-c511-a0484b8837de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------+-----+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+\n",
            "|first_order_month| day0|               day25|               day50|               day75|             day100|              day125|              day150|\n",
            "+-----------------+-----+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+\n",
            "|       2019-10-01|25762| 0.15860569831534818| 0.11695520534120021| 0.10593121652045649|0.10270941697073209|0.053916621380327615|5.434360686282121E-4|\n",
            "|       2019-11-01|26761| 0.07895818541908001| 0.08336758716042002| 0.07096147378648032| 0.0202907215724375|                 0.0|                 0.0|\n",
            "|       2019-12-01|19702| 0.06999289412242411| 0.05238046898792001|0.012283016952593645|                0.0|                 0.0|                 0.0|\n",
            "|       2020-01-01|20427|0.054192979879571154|0.003671611102951...|                 0.0|                0.0|                 0.0|                 0.0|\n",
            "|       2020-02-01|17866|0.001231389230941453|                 0.0|                 0.0|                0.0|                 0.0|                 0.0|\n",
            "+-----------------+-----+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# try 1\n",
        "result = spark.sql(\"\"\"\n",
        "WITH stats AS (\n",
        "  SELECT user_id\n",
        "       , DATE_FORMAT(MIN(event_time), 'yyyy-MM-dd') AS first_order_date\n",
        "       , DATE_FORMAT(MAX(event_time), 'yyyy-MM-dd') AS last_order_date\n",
        "  FROM new\n",
        "  WHERE event_type = 'purchase'\n",
        "  GROUP BY user_id\n",
        "), processed AS (\n",
        "  SELECT t.user_id\n",
        "       , DATE_FORMAT(s.first_order_date, 'yyyy-MM-01') AS first_order_month\n",
        "       , DATE_FORMAT(t.event_time, 'yyyy-MM-dd') AS order_date\n",
        "       , first_order_date\n",
        "  FROM new t\n",
        "    INNER JOIN stats s ON t.user_id = s.user_id AND t.event_type = 'purchase'\n",
        ")\n",
        "SELECT first_order_month\n",
        "     , COUNT(DISTINCT user_id) AS day0\n",
        "     , COUNT(DISTINCT CASE WHEN order_date >= DATE_ADD(first_order_date, 25) AND order_date < DATE_ADD(first_order_date, 50) THEN user_id END) / COUNT(DISTINCT user_id) AS day25\n",
        "     , COUNT(DISTINCT CASE WHEN order_date >= DATE_ADD(first_order_date, 50) AND order_date < DATE_ADD(first_order_date, 75) THEN user_id END) / COUNT(DISTINCT user_id) AS day50\n",
        "     , COUNT(DISTINCT CASE WHEN order_date >= DATE_ADD(first_order_date, 75) AND order_date < DATE_ADD(first_order_date, 100) THEN user_id END) / COUNT(DISTINCT user_id) AS day75\n",
        "     , COUNT(DISTINCT CASE WHEN order_date >= DATE_ADD(first_order_date, 100) AND order_date < DATE_ADD(first_order_date, 125) THEN user_id END) / COUNT(DISTINCT user_id) AS day100\n",
        "     , COUNT(DISTINCT CASE WHEN order_date >= DATE_ADD(first_order_date, 125) AND order_date < DATE_ADD(first_order_date, 150) THEN user_id END) / COUNT(DISTINCT user_id) AS day125\n",
        "     , COUNT(DISTINCT CASE WHEN order_date >= DATE_ADD(first_order_date, 150) AND order_date < DATE_ADD(first_order_date, 175) THEN user_id END) / COUNT(DISTINCT user_id) AS day150\n",
        "FROM processed\n",
        "GROUP BY first_order_month\n",
        "ORDER BY first_order_month\n",
        "\n",
        "\"\"\")\n",
        "result.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3khDLKUOrnyk",
        "outputId": "c54477e5-6144-4990-bbaf-4416e22249bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------+-----+-----+-----+-----+------+------+------+\n",
            "|first_order_month| day0|day25|day50|day75|day100|day125|day150|\n",
            "+-----------------+-----+-----+-----+-----+------+------+------+\n",
            "|       2019-10-01|25762| 4086| 3013| 2729|  2646|  1389|    14|\n",
            "|       2019-11-01|26761| 2113| 2231| 1899|   543|     0|     0|\n",
            "|       2019-12-01|19702| 1379| 1032|  242|     0|     0|     0|\n",
            "|       2020-01-01|20427| 1107|   75|    0|     0|     0|     0|\n",
            "|       2020-02-01|17866|   22|    0|    0|     0|     0|     0|\n",
            "+-----------------+-----+-----+-----+-----+------+------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# try 2\n",
        "# 첫구매 월별 구매자 수 확인\n",
        "result = spark.sql(\"\"\"\n",
        "WITH stats AS (\n",
        "  SELECT user_id\n",
        "       , DATE_FORMAT(MIN(event_time), 'yyyy-MM-dd') AS first_order_date\n",
        "       , DATE_FORMAT(MAX(event_time), 'yyyy-MM-dd') AS last_order_date\n",
        "  FROM new\n",
        "  WHERE event_type = 'purchase'\n",
        "  GROUP BY user_id\n",
        "), processed AS (\n",
        "  SELECT t.user_id\n",
        "       , DATE_FORMAT(s.first_order_date, 'yyyy-MM-01') AS first_order_month\n",
        "       , DATE_FORMAT(t.event_time, 'yyyy-MM-dd') AS order_date\n",
        "       , first_order_date\n",
        "  FROM new t\n",
        "    INNER JOIN stats s ON t.user_id = s.user_id AND t.event_type = 'purchase'\n",
        ")\n",
        "SELECT first_order_month\n",
        "     , COUNT(DISTINCT user_id) AS day0\n",
        "     , COUNT(DISTINCT CASE WHEN order_date >= DATE_ADD(first_order_date, 25) AND order_date < DATE_ADD(first_order_date, 50) THEN user_id END) AS day25\n",
        "     , COUNT(DISTINCT CASE WHEN order_date >= DATE_ADD(first_order_date, 50) AND order_date < DATE_ADD(first_order_date, 75) THEN user_id END) AS day50\n",
        "     , COUNT(DISTINCT CASE WHEN order_date >= DATE_ADD(first_order_date, 75) AND order_date < DATE_ADD(first_order_date, 100) THEN user_id END) AS day75\n",
        "     , COUNT(DISTINCT CASE WHEN order_date >= DATE_ADD(first_order_date, 100) AND order_date < DATE_ADD(first_order_date, 125) THEN user_id END) AS day100\n",
        "     , COUNT(DISTINCT CASE WHEN order_date >= DATE_ADD(first_order_date, 125) AND order_date < DATE_ADD(first_order_date, 150) THEN user_id END) AS day125\n",
        "     , COUNT(DISTINCT CASE WHEN order_date >= DATE_ADD(first_order_date, 150) AND order_date < DATE_ADD(first_order_date, 175) THEN user_id END) AS day150\n",
        "FROM processed\n",
        "GROUP BY first_order_month\n",
        "ORDER BY first_order_month\n",
        "\n",
        "\"\"\")\n",
        "result.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMC69RglnJKmiNXxvrKYlGq"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
